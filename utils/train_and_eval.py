from tqdm import tqdm
from torch.amp import GradScaler, autocast
import torch
import numpy as np
import torch.nn.functional as F
"""
è®­ç»ƒå’ŒéªŒè¯
"""
def total_loss(model_output, target, loss_fn):
    """
    model_output: é¢„æµ‹å€¼
    target: çœŸå®å€¼
    loss_fn: æŸå¤±å‡½æ•°
    """
    # è·å–æ€»çš„æŸå¤± TODO: ä½¿ç”¨å­—å…¸å­˜å‚¨æŸå¤±
    loss_dict_list = [loss_fn(F.softmax(model_output[i], dim=1), target) for i in range(len(model_output))]

    total_losses = torch.tensor(0.0, dtype=torch.float32, device="cuda:0")
    OM_losses = torch.tensor(0.0, dtype=torch.float32, device="cuda:0")
    OP_losses = torch.tensor(0.0, dtype=torch.float32, device="cuda:0")
    IOP_losses = torch.tensor(0.0, dtype=torch.float32, device="cuda:0")

    # éå†æ¯ä¸€å±‚æŸå¤±
    for loss_dict in loss_dict_list: 
        # OM_loss = loss_dict['Organic matter']   # list:[8]
        # OP_loss = loss_dict['Organic pores']
        # IOP_loss = loss_dict['Inorganic pores']
        total_loss = loss_dict['total_loss']
        
        # ç´¯åŠ æŸå¤±
        total_losses += total_loss
        # OM_losses += OM_loss
        # OP_losses += OP_loss
        # IOP_losses += IOP_loss
    
    # è®¡ç®— 7å±‚ å¹³å‡æŸå¤±
    total_loss =  total_losses / len(loss_dict_list)
    # OM_loss = OM_losses / len(loss_dict_list)
    # OP_loss = OP_losses / len(loss_dict_list) 
    # IOP_loss = IOP_losses / len(loss_dict_list) 

    return total_loss
  

def train_one_epoch(model, optimizer, epoch, train_dataloader, device, loss_fn, scaler, elnloss, l1_lambda, l2_lambda):
    """"
    model:             æ¨¡å‹
    optimizer:         ä¼˜åŒ–å™¨
    epoch:             å½“å‰epoch
    train_dataloader:  è®­ç»ƒæ•°æ®é›†
    device:            è®¾å¤‡
    loss_fn:           æŸå¤±å‡½æ•°
    scaler:            æ¢¯åº¦ç¼©æ”¾å™¨
    elnloss:           æ˜¯å¦ä½¿ç”¨Elastic Netæ­£åˆ™åŒ–
    l1_lambda:         l1æ­£åˆ™åŒ–ç³»æ•°
    l2_lambda:         l2æ­£åˆ™åŒ–ç³»æ•°
    """
    
    model.train()
    
    epoch_train_loss = 0.0
    epoch_OM_loss = 0.0
    epoch_OP_loss = 0.0
    epoch_IOP_loss = 0.0

    # ä½¿ç”¨ tqdm åŒ…è£… train_dataloader
    train_dataloader = tqdm(train_dataloader, desc=f" Training on Epoch :{epoch + 1}ğŸ˜€", leave=False)
    
    for data in train_dataloader: 
        # è·å–è®­ç»ƒæ•°æ®é›†çš„ä¸€ä¸ªbatch
        images, masks = data
        images, masks = images.to(device), masks.to(device)
        # æ¢¯åº¦æ¸…é›¶
        optimizer.zero_grad()
        
        # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        with autocast(device_type="cuda"):
            # è®­ç»ƒ + è®¡ç®—loss
            # pred_masksï¼šlist:(7, pred_mask)
            pred_masks = model(images)  #  è®­ç»ƒè¾“å‡º 7 ä¸ªé¢„æµ‹ç»“æœï¼Œ6 ä¸ªè§£ç å™¨è¾“å‡ºå’Œ 1 ä¸ªæ€»è¾“å‡ºã€‚

            if isinstance(pred_masks, list):
                train_mean_loss = total_loss(pred_masks, masks, loss_fn)
                
                # if elnloss:
                #     # æ·»åŠ Elastic Netæ­£åˆ™åŒ–
                #     elastic_net_loss = model.elastic_net(l1_lambda=l1_lambda, l2_lambda=l2_lambda)
                #     train_mean_loss = train_mean_loss + elastic_net_loss
              
            else:
                loss_dict = loss_fn(pred_masks, masks)
                train_mean_loss = loss_dict['total_loss']
                
                # if elnloss:
                #     # æ·»åŠ Elastic Netæ­£åˆ™åŒ–
                #     elastic_net_loss = model.elastic_net(l1_lambda=l1_lambda, l2_lambda=l2_lambda)
                #     train_mean_loss = train_mean_loss + elastic_net_loss
            

        # åå‘ä¼ æ’­
        scaler.scale(train_mean_loss).backward()

        
        # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦åŒ…å«infæˆ–nan
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

        # æ›´æ–°å‚æ•°
        scaler.step(optimizer)
        
        # æ›´æ–°æ¢¯åº¦ç¼©æ”¾å™¨
        scaler.update()

        epoch_train_loss += train_mean_loss.item()
        # epoch_OM_loss += OM_loss.item()
        # epoch_OP_loss += OP_loss.item()
        # epoch_IOP_loss += IOP_loss.item()
        
    return epoch_train_loss

def evaluate(model, device, data_loader, loss_fn, Metric, test:bool=False):
    """
    model:       æ¨¡å‹
    device:      è®¾å¤‡
    data_loader: æ•°æ®é›†
    loss_fn:     æŸå¤±å‡½æ•°
    Metric:      æŒ‡æ ‡
    """
    model.eval()
    if test:
        Metric_list = np.zeros((6, 4))
    else:
        Metric_list = np.zeros((6, 4))
    val_mean_loss = 0.0
    val_OM_loss = 0.0
    val_OP_loss = 0.0
    val_IOP_loss = 0.0


    with torch.no_grad():
        val_dataloader = tqdm(data_loader, desc=f"  Validating  ğŸ˜€", leave=False)
        for data in val_dataloader:
            images, masks =data[0].to(device), data[1].to(device)
            with autocast(device_type="cuda"):
                pred_mask = model(images)         # éªŒè¯  æ¨¡å‹ softmax è¾“å‡º
                loss_dict = loss_fn(pred_mask, masks)
           
                masks = masks.to(torch.int64)
                masks = masks.squeeze(1)
                metrics = Metric.update(pred_mask, masks)
                Metric_list += metrics    

            # ç´¯åŠ æŸå¤±   # TODO : 2
            val_mean_loss += loss_dict['total_loss'].item()
            val_OM_loss += loss_dict['Organic matter'].item()
            val_OP_loss += loss_dict['Organic pores'].item()
            val_IOP_loss += loss_dict['Inorganic pores'].item()
    
    Metric_list /= len(val_dataloader)

    # TODO : 3
    return val_mean_loss,val_OM_loss,val_OP_loss,val_IOP_loss, Metric_list
