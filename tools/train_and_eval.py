from tqdm import tqdm
from torch.amp import GradScaler, autocast
import torch
import numpy as np
import torch.nn.functional as F
"""
è®­ç»ƒå’ŒéªŒè¯
"""
def _total_loss(model_outputs, target, loss_fn, class_names):
    """
    model_output: é¢„æµ‹å€¼
    target: çœŸå®å€¼
    loss_fn: æŸå¤±å‡½æ•°
    """
    # åˆ›å»ºæŸå¤±å­—å…¸
    loss_dict = {cls:0.0 for cls in class_names}
    loss_dict['total_loss'] = 0.0
    # è·å–æ¯ä¸€å±‚çš„æŸå¤±
    loss_dict_list = [loss_fn(F.softmax(model_output, dim=1), target) for model_output in model_outputs]

    for i in loss_dict_list: 
        for cls in class_names:
            loss_dict[cls] += i[cls]
        loss_dict['total_loss'] += i['total_loss'] 
    
    # è®¡ç®—å¹³å‡æŸå¤±
    for cls in class_names:
        loss_dict[cls] /= len(loss_dict_list)
    loss_dict['total_loss'] /= len(loss_dict_list)
    return loss_dict

def train_one_epoch(model, optimizer, epoch, train_dataloader, device, loss_fn, scaler, Metric, scheduler, class_names, elnloss, l1_lambda, l2_lambda):
    """"
    model:             æ¨¡å‹
    optimizer:         ä¼˜åŒ–å™¨
    epoch:             å½“å‰epoch
    train_dataloader:  è®­ç»ƒæ•°æ®é›†
    device:            è®¾å¤‡
    loss_fn:           æŸå¤±å‡½æ•°
    scaler:            æ¢¯åº¦ç¼©æ”¾å™¨
    scheduler:         è°ƒåº¦å™¨
    elnloss:           æ˜¯å¦ä½¿ç”¨Elastic Netæ­£åˆ™åŒ–
    l1_lambda:         l1æ­£åˆ™åŒ–ç³»æ•°
    l2_lambda:         l2æ­£åˆ™åŒ–ç³»æ•°
    """
    model.train()
    Metric_list = np.zeros((6, len(class_names)+1))
    train_dataloader = tqdm(train_dataloader, desc=f" Training on Epoch :{epoch + 1}ğŸ˜€", leave=False)
    epoch_losses = [0.0] * len(class_names+ ['total'])  # åŠ ä¸Šæ€»æŸå¤±
    
    for data in train_dataloader: 
        # è·å–è®­ç»ƒæ•°æ®é›†çš„ä¸€ä¸ªbatch
        images, masks = data[0][0], data[0][1]
        images, masks = images.to(device), masks.to(device)
        # æ¢¯åº¦æ¸…é›¶
        optimizer.zero_grad()
        
        # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        with autocast(device_type="cuda"):
            pred = model(images)  
            masks = masks.to(torch.int64)

            # U2Net
            if isinstance(pred, list):
                loss_dict = _total_loss(pred, masks, loss_fn, class_names)  #  è®­ç»ƒè¾“å‡º 7 ä¸ªé¢„æµ‹ç»“æœï¼Œ6 ä¸ªè§£ç å™¨è¾“å‡ºå’Œ 1 ä¸ªæ€»è¾“å‡ºã€‚
                losses = loss_dict.values()
                total_loss = loss_dict['total_loss']
                if elnloss:
                    # æ·»åŠ Elastic Netæ­£åˆ™åŒ–
                    elastic_net_loss = model.elastic_net(l1_lambda=l1_lambda, l2_lambda=l2_lambda)
                    total_loss = total_loss + elastic_net_loss
                metrics = Metric.update(pred, masks)
                Metric_list += metrics
            
            # æ˜¯å¦ä½¿ç”¨è¾…åŠ©åˆ†ç±»å™¨
            elif isinstance(pred, tuple):
                if len(pred) == 2:
                    heatmap, aux = pred
                    # ä¸»åˆ†æ”¯loss
                    main_loss_dict = loss_fn(heatmap, masks)
                    main_losses = main_loss_dict.values()
                    
                    # è¾…åŠ©åˆ†æ”¯loss
                    aux_loss_dict = loss_fn(aux, masks)
                    aux_losses = aux_loss_dict.values()
                    
                    # è®¡ç®—æ€»æŸå¤±ï¼šä¸»åˆ†æ”¯æŸå¤±*0.6 + è¾…åŠ©åˆ†æ”¯æŸå¤±*0.4
                    losses = [m_loss*0.6 + a_loss*0.4 for m_loss, a_loss in zip(main_losses, aux_losses)]
                    total_loss = losses[-1]
                    if elnloss:
                        # æ·»åŠ Elastic Netæ­£åˆ™åŒ–
                        elastic_net_loss = model.elastic_net(l1_lambda=l1_lambda, l2_lambda=l2_lambda)
                        total_loss = total_loss + elastic_net_loss
                    metrics = Metric.update(heatmap, masks)
                    Metric_list += metrics
            else:
                loss_dict = loss_fn(pred, masks)
                losses = loss_dict.values()
                total_loss = loss_dict['total_loss']
                if elnloss:
                    # æ·»åŠ Elastic Netæ­£åˆ™åŒ–
                    elastic_net_loss = model.elastic_net(l1_lambda=l1_lambda, l2_lambda=l2_lambda)
                    total_loss = total_loss + elastic_net_loss
                metrics = Metric.update(pred, masks)
                Metric_list += metrics

        # åå‘ä¼ æ’­
        scaler.scale(total_loss).backward()
      
        # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦åŒ…å«infæˆ–nan
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

        # æ›´æ–°å‚æ•°
        scaler.step(optimizer)
        scaler.update()
        scheduler.step()
        epoch_losses = [x+y for x, y in zip(epoch_losses, losses)]

    Metric_list /= len(train_dataloader)
    return  epoch_losses, Metric_list   

def evaluate(model, device, data_loader, loss_fn, Metric, class_names, test:bool=False):
    """
    model:       æ¨¡å‹
    device:      è®¾å¤‡
    data_loader: æ•°æ®é›†
    loss_fn:     æŸå¤±å‡½æ•°
    Metric:      æŒ‡æ ‡
    """
    model.eval()
    if test:
        Metric_list = np.zeros((6, len(class_names)+1))
    else:
        Metric_list = np.zeros((6, len(class_names)+1))
    epoch_losses = [0.0] * len(class_names+['total'])  # åŠ ä¸Šæ€»æŸå¤±

    with torch.no_grad():
        val_dataloader = tqdm(data_loader, desc=f"  Validating  ğŸ˜€", leave=False)
        for data in val_dataloader:
            images, masks =data[0][0].to(device), data[0][1].to(device)
            with autocast(device_type="cuda"):
                pred_mask = model(images)         # éªŒè¯  æ¨¡å‹ softmax è¾“å‡º
                masks = masks.to(torch.int64)
                masks = masks.squeeze(1)
                # U2Net
                if isinstance(pred_mask, list):
                    loss_dict = _total_loss(pred_mask, masks, loss_fn, class_names)  #  è®­ç»ƒè¾“å‡º 7 ä¸ªé¢„æµ‹ç»“æœï¼Œ6 ä¸ªè§£ç å™¨è¾“å‡ºå’Œ 1 ä¸ªæ€»è¾“å‡ºã€‚
                    losses = loss_dict.values()
                    total_loss = loss_dict['total_loss']
                    metrics = Metric.update(pred_mask, masks)
                    Metric_list += metrics

                # æ˜¯å¦ä½¿ç”¨è¾…åŠ©åˆ†ç±»å™¨
                elif isinstance(pred_mask, tuple):
                    heatmap, aux = pred_mask
                    # ä¸»åˆ†æ”¯loss
                    main_loss_dict = loss_fn(heatmap, masks)
                    main_losses = main_loss_dict.values()
                    # è¾…åŠ©åˆ†æ”¯loss
                    aux_loss_dict = loss_fn(aux, masks)
                    aux_losses = aux_loss_dict.values()
                    # è®¡ç®—æ€»æŸå¤±ï¼šä¸»åˆ†æ”¯æŸå¤±*0.6 + è¾…åŠ©åˆ†æ”¯æŸå¤±*0.4
                    losses = [m_loss*0.6 + a_loss*0.4 for m_loss, a_loss in zip(main_losses, aux_losses)]
                    total_loss = losses[-1]
                    metrics = Metric.update(heatmap, masks)
                    Metric_list += metrics    

                else:
                    loss_dict = loss_fn(pred_mask, masks)
                    losses = loss_dict.values()
                    metrics = Metric.update(pred_mask, masks)
                    Metric_list += metrics    

            # ç´¯åŠ æŸå¤± 
            epoch_losses = [x+y for x, y in zip(epoch_losses, losses)]
    Metric_list /= len(val_dataloader)
    return  epoch_losses, Metric_list
